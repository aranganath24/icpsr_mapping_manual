# Tutorial

```{r, include=FALSE}
library(tmap)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(rgeos)
library(tidyverse)
library(readxl)
library(dplyr)
```

## Load and View Data 

Now that we've taken care of those preliminary steps, let's bring in the tutorial data into our R environment so that we can begin working with it. There are two pieces of data we'll need to load:

* The ICPSR tabular dataset on government policy responses to Covid-19 (Section 4.1.1)
* A spatial dataset of world country boundaries; we will bring this dataset into R Studio via the ```ne_countries``` function of the "rnaturalearth" package (Section 4.1.2)

### ICPSR Covid-19 Tabular Data

When importing tabular data that you have saved on our computer into R Studio, it's important to first understand some of the details of the data we're trying to import. The first thing to note is the type of file we're working with, which is indicated by the file extension; here, we can note that the ICPSR data is a .xlsx file, which means that it's an Excel file (but note that .xlsx files can also be opened in spreadsheet software programs other than Excel). That means we'll have to import it into R Studio using a function designed specifically to handle Excel files. To that end, we'll use the ```read_excel``` function from the *readxl* package. Recall that if you want to learn more about a function or a package, simply type a question mark followed by the package or function name in the console, and relevant information will appear in the "Help" tab of the "Files/Plots/Packages/Help/Viewer" window on the bottom right of our R Studio interface. For example, if we wanted to learn more about the ```read_excel```function, we would type ```?read_excel``` into the console. 

Before using the ```read_excel``` function to bring in the , it could be helpful to open up the data outside the R environment to see whether the dataset has any features that we have to account for when loading it into our R environment. When we first open the spreadsheet, it will look something like this:

```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='ICPSR Dataset in Spreadsheet: Description Tab'}
knitr::include_graphics('images/excel_open.png')
```

Note that when we open the spreadsheet, we land on its first tab (or "sheet"), which is titled "Description". This part of the spreadsheet effectively functions as a data codebook, which we can look through to understand the dataset's various variables and and assess how they were measured. To open up the actual dataset, we can toggle to the "Dataset" tab by pressing the corresponding button on the bottom-left of the spreadsheet (highlighted in red below): 

```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='ICPSR Dataset in Spreadsheet: Dataset Tab'}
knitr::include_graphics('images/excel_tabs.png')
```

The fact that the ICPSR dataset has two sheets within it is important; it means that when we load it into R, we'll have to explicitly specify the sheet (i.e. the "Dataset" sheet) we want to import. 

Now, let's go ahead and load the "Dataset" sheet of the ICPSR data file. Type the following code into your script, and run it:

```{r, echo=-1}
setwd("/Users/adityaranganath/Documents/git_repositories/icpsr_mapping_manual/tutorial_data")
# Imports "Dataset" sheet from ICPSR Excel file into R Studio, and assigns the dataset to an object called "covid_data"
covid_data<-read_excel("Gov_Responses2Covid19_last.xlsx", sheet="Dataset")
```

Let's unpack that code. As we noted above, ```read_excel``` is the function used to bring in Excel spreadsheet data into R. The function has two arguments; the first ("Gov_Responses2Covid19_last.xlsx") is the name of the file we want to import, while the second (sheet="Dataset") specifies that we specifically want to import the the "Dataset" sheet from that Excel file. This code is then assigned, using ```<-``` (R's assignment operator) to a new object that we call ```covid_data```. This means that the output of the code on the right hand side of the assignment operator is now assigned to the ```covid_data``` object. Think of this object as a container of sorts, one which holds, or "contains", the output of the code to the right of the assignment operator. Object assignment isn't necessary; we could have brought the data into R Studio by simply typing the code to the right of the assignment operator. However, assigning the dataset to an object allows for the more flexible and intuitive handling of data, so it is a common practice. 

Note that after typing the code from the previous codeblock into your R script and running it, you still won't actually see the dataset within the R environment. There are many ways to pull up and inspect the data; in this tutorial, we'll use the ```View``` function, which will bring up the data as a separate tab in the "Source" window. To display the contents of the ```covid_data``` object (in other words, the dataset we just imported), type and run the following code: 

```{r}
# Brings up dataset held in the "covid_data" object in R Studio's data viewer
View(covid_data)
```

Within your R Studio environment, the result of running ```View(covid_data)``` will look something like this (dataset outlined in red):

```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='Viewing ICPSR Dataset in R Environment'}
knitr::include_graphics('images/viewdata.png')
```

You can scroll up/down and across the dataset within the data viewer. 

### Country Boundaries Spatial Data

Now that we have our tabular data on government responses to Covid-19 loaded into R Studio, let's bring spatial data on world country borders into memory. Eventually, we'll represent the Covid-19 data on a map by joining it to the spatial data on country boundaries that we will now bring in.

When working with spatial data in R, you will sometimes want to import data that you collected on your own, or data that you downloaded. There are several functions in the ```sf``` package that will allow you to easily import your external spatial data in R; if you need to do this, you should consult the package's documentation.

In our case, we won't have to download and import the spatial data we need into R Studio, since there are R packages that already contain this spatial data. In particular, we'll use the ```ne_countries``` function of the *rnaturalearth* package to bring the country border dataset into our R environment. Note the two arguments we pass into the ```ne_countries``` function: the "scale" argument specifies that we want to use a medium scale when rendering the map (the other options are 'small' and 'large'), while the "returnclass" argument specifies that we want the spatial dataset in 'sf' format, which is a spatial data format that works well with the *tmap* mapping package we'll use later. As in the previous section, we'll assign the dataset to an object so that we can easily work with it later; we'll call this object "country_boundaries":

```{r}
# Brings spatial dataset of country boundaries into R environment using the rnaturalearth package
country_boundaries<-ne_countries(scale="medium", returnclass="sf")
```

Now that we have this spatial dataset in memory and assigned to an object, let's step back and clarify what exactly a spatial dataset is. In some respects, a spatial dataset is like a typical tabular dataset. To see this, let's pass the "country_boundaries" object through the ```View()``` function to open up the dataset:

```{r}
View(country_boundaries)
```

By scrolling across the dataset, you'll notice that each row corresponds to a country, and that there are many columns that correspond to various country-level attributes. The key column, however, which makes this a spatial dataset (as opposed to merely a tabular one), is the information contained in a column called "geometry". This column contains geographic coordinate information that essentially defines a polygon for each country in the dataset. The "geometry" column is likely one of the last columns in the dataset, so you may have to scroll a bit to find it. Alternatively, we can use the ```relocate``` function in the *dplyr* package to make the "geometry" column the first column in the dataset within "country_boundaries", and then view this reordered dataset using the ```View``` function. The first argument passed to the ```relocate``` function ("country_boundaries") indicates the object that contains the relevant dataset, and the second argument ("geometry) indicates the name of the column we want to move to the front of the dataset. 

```{r}
View(relocate(country_boundaries, geometry))
```

After typing in that code and running it in your script, the window with the reordered dataset should appear in your source window; note the "geometry" tab:

```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='Geometry Column Contains Spatial Information'}
knitr::include_graphics('images/geometry.png')
```

We can use the information in the "geometry" tab to draw georeferenced polygons for each row in the spatial dataset, which will yield a world map! To translate the information in the geometry tab into a cartographic representation, we'll use a package called *tmap*. To bring up the features of the dataset, we have to first tell *tmap* what dataset contains the information we want to map; we do this by first passing the name of the object that contains the relevant dataset (here, "country_boundaries") to the ```tm_shape``` function, and then specifying that our features (i.e. country borders) are represented as polygons through the ```tm_polygons``` function. The ```tm_polygons``` function does not require any arguments. In the *tmap* package, we can connect functions together through a plus sign (+). When we type in and run the following code, the result is a map that is rendered based on the information in the "geometry" column:

```{r, fig.asp=0.5}
# maps geographic features (i.e. countries) of spatial dateset
tm_shape(country_boundaries)+
  tm_polygons()
```

We can assign this map to an object, just as we assigned the ICPSR tabular dataset to an object. Let's call this object "worldmap."

```{r}
# assigns map of geographic features to a new object called "worldmap" 
worldmap<-tm_shape(country_boundaries)+
            tm_polygons()
```

Having assigned the map to the "worldmap" object, we can bring up the map whenever we want by simply calling "worldmap" object: t:

```{r, fig.asp=0.5}
# calls "worldmap" object to display country-level map generated from the "country_boundaries" spatial dataset 
worldmap
```

Within the R Studio interface, we can see the above map within the bottom-right window after selecting the "Plots" tab:

```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='World Map in "Plots" Tab (Rendered from Spatial Dataset'}
knitr::include_graphics('images/worldmap_window.png')
```

We can enlarge the map in this window by clicking the "Zoom" link; this will produce an enlarged version of the map in a separate window:

```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='Enlarging Map with "Zoom" Button'}
knitr::include_graphics('images/zoom2.png')
```

## Edit Spatial Data

We can edit spatial datasets in R Studio with relative ease, using commonly used R packages. Let's say, for example, that we don't want Antarctica to appear on our map (since Antarctica typically does not appear on political maps of the world). 

To delete Antarctica from the map, we first need to delete the row that corresponds to Antarctica from the spatial dataset contained in the "country_boundaries" object. We can do so with the following code:

```{r}
# Deletes Antarctica from spatial dataset in "country_boundaries" object
country_boundaries<-country_boundaries %>% filter(iso_a3 !="ATA")
```

We can translate this code into ordinary language as follows: "Take the existing country boundaries dataset (```country_boundaries``` to the left of the ```%>%``` and after the assignment operator) and then (``` %>% ```, a symbol called a pipe, which is used to chain together code) select only the countries that are not Antarctica (```filter(iso_a3 !="ATA"```). Take this new dataset, which doesn't include Antarctica, and assign it back to the existing 'country_boundaries' object (```country_boundaries<-```), which effectively replaces the previous spatial dataset in the country_boundaries object (which did include Antarctica)." 

Two things may require additional elaboration:

* First is the pipe, the symbol that looks like this: %>%. The pipe operator essentially takes the output of the code on its left, and then use that output as an input to the code on its right. Here, the pipe is taking the output of the Here, the pipe is taking the output of the "country_dataset" object (i.e. the existing spatial dataset) on its left, and then using that output as an input to the ```filter``` function on its right. In other words, the pipe operator links the code on its two sides, and indicates that the object being passed through the ```filter``` function is the "country_boundaries" object. 
* The ```filter``` function  is a function from the *dplyr* package that allows one to select rows from a dataset by specified criteria. In our case, we want to select all rows from the dataset that are not Antarctica. The argument to the ```filter``` function, ```iso_a3 !="ATA"```, is essentially saying "return any records where the iso_a3 variable in the attribute table (the 3-digit ISO country code) is NOT equal to "ATA" (Antarctica's code). Note that ```!=``` is R syntax for "not equal to".^[If we were to instead type ```filter(iso_a3=="ATA)```, the function would *only* select the Antarctica row from the dataset and discard everything else.]

Now, let's see this change reflected in the corresponding map. To do so, we must update the "worldmap" object by rerunning the object assignment. The worldmap object we defined above will not automatically reflect the edits we just made to the "country_boundaries" dataset; we need to run the code again with the edited version of the dataset "country_boundaries" object passed through the ```tm_shape``` function:

```{r}
worldmap<-tm_shape(country_boundaries)+
            tm_polygons()
```

Now, let's view our updated map:

```{r, fig.asp=0.5}
worldmap
```

As desired, Antarctica has been deleted from the spatial dataset, and therefore no longer appears on the corresponding map. 

## Process ICPSR Tabular Data for Mapping

In order to represent the ICPSR data on governments' economic responses to Covid-19 on a map, we must join the ICPSR dataset (contained in the "covid_data" object) to the spatial dataset (contained in the "country_boundaries" object); at that point, we'll have a new, integrated dataset that will include the country-level Covid-19 data of interest in a spatial dataset. We can then display that Covid-19 information on a map by using the ```tmap``` package. 
Before we can take those steps, however, we need to process the ICPSR tabular data with a view towards facilitating the joining and mapping process.

### Select Variables

When working with data in R, it is often useful to get a quick sense of a given dataset's dimensions, which we can do using the ```dim``` function. Below, we pass the "covid_data" object through the ```dim``` function:

```{r}
dim(covid_data)
```

The output indicates that there are 62700 rows in the dataset, and 43 columns. This suggests that there are quite a few variables in the dataset. Given that we're only interested in mapping (for now) the variable that represents an aggregate index (computed from other variables in the dataset) of the generosity of governments' economic support measures in response to the pandemic, we'll go ahead and delete superfluous columns so as to keep the size of the final (joined) dataset tractable. The name of the variable we'd like to map, and therefore keep, is "Economic_Measure" (see the dataset's documentation for more details). In addition to keeping this variable, we also need to keep a column titled "iso", which is the 3-digit ISO country code; this ISO code also exists in the spatial dataset to which we want to join the "Economic_Measure" variable, and so we will use these ISO codes as the joining variable. 

Let's create a new object, which we'll call "covid_data_economic", to contain this smaller dataset comprised of the ISO code and the economic interventions index we're interested in mapping:

```{r}
covid_data_economic<-covid_data %>% 
                      select(iso, Economic_Measures) 
```

The above code can be translated as follows: "Start with the dataset in the 'covid_data' object ('covid_data'), and then keep the 'iso' and 'Economic_Measures' columns but discard everything else ('select(iso, Economic_Measures)). Assign this new 2-column dataset to a new object called 'covid_data_economic' ('covid_data_economic<-')." We can take a look at this smaller dataset extracted from the original dataset by passing the "covid_data_economic" object as an argument to the now-familiar ```View``` function:

```{r}
View(covid_data_economic)
```

Within the "Source" window, a new tab that contains the smaller 2-column dataset that is within the "covid_data_economic" object will appear:


```{r, echo=FALSE, results='asis', out.width='100%', fig.cap='New Dataset Based on Selection from Original Dataset'}
knitr::include_graphics('images/selection.png')
```

Note that the original Covid-19 policy responses dataset, stored in the "covid_data" object, is unaffected by our creation of a new dataset based on the selection of these two variables. You can confirm that this original data is still stored in the "covid_data" object by opening it up:

```{r}
View(covid_data)
```

We can go back to this initial dataset (in the "covid_data" object) anytime we might need, but for now we'll set it aside and start working with our newly created dataset in the "covid_data_economic" object. 

### Change class of "Economic_Measures" Index



### Compute average of "Economic_Measures" index

### Calculate Summary Statistics







